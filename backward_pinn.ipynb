{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import random\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ],
   "id": "ec1b204a8293a0ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "c909e570ab558071",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(321)\n",
    "np.random.seed(321)\n",
    "torch.manual_seed(321)\n",
    "torch.cuda.manual_seed_all(321)"
   ],
   "id": "a27446baeed6330f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BackwardModel(nn.Module):\n",
    "    def __init__(self, in_size, out_size, hidden_size, activation):\n",
    "        super(BackwardModel, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.lambda1 = nn.Parameter(torch.tensor([0.2], requires_grad=True).to(device))\n",
    "        self.lambda2 = nn.Parameter(torch.tensor([-5.0], requires_grad=True).to(device))\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            self.activation(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            self.activation(),\n",
    "            nn.Linear(hidden_size, out_size)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        return self.layers(torch.stack(args, dim=1)).flatten()"
   ],
   "id": "131cb4bd4bba9888",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PBLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PBLoss, self).__init__()\n",
    "\n",
    "    def forward(self, model: BackwardModel, x, t, u_pred, u):\n",
    "        u_t = torch.autograd.grad(\n",
    "            u_pred, t,\n",
    "            grad_outputs=torch.ones_like(u_pred),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_x = torch.autograd.grad(\n",
    "            u_pred, x,\n",
    "            grad_outputs=torch.ones_like(u_pred),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x,\n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        loss1 = (u_t + torch.exp(model.lambda1) * u * u_x - torch.exp(model.lambda2) * u_xx).pow(2).mean()\n",
    "        loss2 = (u_pred - u).pow(2).mean().nan_to_num(nan=0.0)\n",
    "\n",
    "        return loss1 + loss2"
   ],
   "id": "df4663606f773fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from random import randint\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, t, x, u):\n",
    "        super(CustomDataset).__init__()\n",
    "        self.t = t\n",
    "        self.x = x\n",
    "        self.u = u\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.t[item], self.x[item], self.u[item]\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    data = scipy.io.loadmat(path)\n",
    "\n",
    "    T = data['t'].flatten()[:, None]\n",
    "    X = data['x'].flatten()[:, None]\n",
    "    U = np.real(data['usol']).T\n",
    "\n",
    "    t, x, u = [], [], []\n",
    "    for i, t_curr in enumerate(T):\n",
    "        for j, x_curr in enumerate(X):\n",
    "            t.append(torch.Tensor(np.array(t_curr)))\n",
    "            x.append(torch.Tensor(np.array(x_curr)))\n",
    "            u.append(torch.Tensor(np.array(U[i][j])))\n",
    "\n",
    "    samples_cnt = 30000\n",
    "    for i in range(samples_cnt):\n",
    "        tp = randint(0,1)\n",
    "        if tp==0:\n",
    "            t.append(torch.rand(1))\n",
    "            x.append(torch.tensor(1))\n",
    "            u.append(torch.tensor(0))\n",
    "        if tp==1:\n",
    "            t.append(torch.rand(1))\n",
    "            x.append(torch.tensor(-1))\n",
    "            u.append(torch.tensor(0))\n",
    "\n",
    "    t = torch.Tensor(t)\n",
    "    x = torch.Tensor(x)\n",
    "    u = torch.Tensor(u)\n",
    "\n",
    "    return CustomDataset(t, x, u)"
   ],
   "id": "cc279260c985775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_log(loss, example_ct, epoch, lambda1, lambda2):\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"loss\": loss,\n",
    "        \"lambda1\": torch.exp(lambda1),\n",
    "        \"lambda2\": torch.exp(lambda2)\n",
    "    }, step=example_ct\n",
    "    )\n",
    "\n",
    "\n",
    "def train(model, loader, criterion, optimizer, config):\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    total_batches = len(loader) * config.epochs\n",
    "    example_ct = 0\n",
    "    batch_ct = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        for _, (t, x, u) in enumerate(loader):\n",
    "            loss = train_batch(t, x, u, model, optimizer, criterion)\n",
    "            example_ct += len(t)\n",
    "            batch_ct += 1\n",
    "\n",
    "            if (batch_ct + 1) % 25 == 0:\n",
    "                train_log(loss, example_ct, epoch, model.lambda1, model.lambda2)\n",
    "\n",
    "\n",
    "def train_batch(t, x, u, model, optimizer, criterion):\n",
    "    t = t.to(device)\n",
    "    x = x.to(device)\n",
    "    t.requires_grad = True\n",
    "    x.requires_grad = True\n",
    "    u_pred = model(t, x)\n",
    "\n",
    "    loss = criterion(model, t, x, u_pred, u)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ],
   "id": "bbd2b9ba81e6c2ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    with wandb.init(project=\"PINN Backward model\", config=hyperparameters):\n",
    "        config = wandb.config\n",
    "        model = BackwardModel(\n",
    "            in_size=2,\n",
    "            out_size=1,\n",
    "            hidden_size=64,\n",
    "            activation=nn.Tanh\n",
    "        )\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=config.learning_rate,\n",
    "        )\n",
    "        criterion = PBLoss()\n",
    "        dataset = load_data(config.dataset)\n",
    "\n",
    "        train_dataset, test_dataset = random_split(\n",
    "            dataset,\n",
    "            (int(len(dataset) * config.test_size), len(dataset) - int(len(dataset) * config.test_size)),\n",
    "            generator=torch.Generator()\n",
    "        )\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "        train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "    return model"
   ],
   "id": "eefc4a527f3c7ea1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params = dict(\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.005,\n",
    "    test_size=0.8,\n",
    "    dataset=\"burgers_shock.mat\",\n",
    ")\n",
    "model = model_pipeline(params)"
   ],
   "id": "823b09dc1555c4d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "res = 256\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "for it in range(0,11):\n",
    "    T = 0.1 * it\n",
    "    t, x, u = [], [], []\n",
    "    for i in range(256):\n",
    "        X = torch.Tensor([-1 + i * (2 / 256)])\n",
    "        # pr10int(X)\n",
    "        t.append(torch.tensor([T]))\n",
    "        x.append(X)\n",
    "\n",
    "    t = torch.Tensor(t)\n",
    "    x = torch.Tensor(x)\n",
    "\n",
    "    pred = model(t, x)\n",
    "    # plt.xlim(-1,1)\n",
    "    # plt.ylim(-1,1)\n",
    "    plt.plot(x.detach().numpy(), pred.detach().numpy(), markersize=3)\n",
    "# plt.savefig(f\"./images/{it}.png\")"
   ],
   "id": "fb12bb502ae8ccb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(model)",
   "id": "ba13c5c23badc3c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6d9aff962d13d83d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fb2fe54f4f340ec2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
