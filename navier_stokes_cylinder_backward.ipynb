{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import math\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sns.set_theme(style='darkgrid')"
   ],
   "id": "8d8d3bcdc187fb78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "85b9a967a3185c04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y, t, u, v, p):\n",
    "        super(CustomDataset, self).__init__()\n",
    "\n",
    "        self.x = torch.Tensor(x).flatten()\n",
    "        self.y = torch.Tensor(y).flatten()\n",
    "        self.t = torch.Tensor(t).flatten()\n",
    "\n",
    "        self.u = torch.Tensor(u).flatten()\n",
    "        self.v = torch.Tensor(v).flatten()\n",
    "        self.p = torch.Tensor(p).flatten()\n",
    "\n",
    "        mask = self.t <= 20\n",
    "        self.x, self.y, self.t = self.x[mask], self.y[mask], self.t[mask]\n",
    "        self.u, self.v, self.p = self.u[mask], self.v[mask], self.p[mask]\n",
    "\n",
    "        self.x_size = len(np.unique(self.x))\n",
    "        self.y_size = len(np.unique(self.y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x[item], self.y[item], self.t[item], self.u[item], self.v[item], self.p[item]\n",
    "\n",
    "\n",
    "def load_data(path) -> CustomDataset:\n",
    "    data = scipy.io.loadmat(path)\n",
    "\n",
    "    u_star = data['U_star']\n",
    "    p_star = data['p_star']\n",
    "    t_star = data['t']\n",
    "    x_star = data['X_star']\n",
    "\n",
    "    n = x_star.shape[0]\n",
    "    t = t_star.shape[0]\n",
    "\n",
    "    x = np.tile(x_star[:, 0:1], (1, t))\n",
    "    y = np.tile(x_star[:, 1:2], (1, t))\n",
    "    t = np.tile(t_star, (1, n)).T\n",
    "\n",
    "    u = u_star[:, 0, :]\n",
    "    v = u_star[:, 1, :]\n",
    "    p = p_star\n",
    "\n",
    "    x = x.flatten()[:, None]\n",
    "    y = y.flatten()[:, None]\n",
    "    t = t.flatten()[:, None]\n",
    "\n",
    "    u = u.flatten()[:, None]\n",
    "    v = v.flatten()[:, None]\n",
    "    p = p.flatten()[:, None]\n",
    "\n",
    "    p -= p.min()\n",
    "\n",
    "    return CustomDataset(x, y, t, u, v, p)"
   ],
   "id": "89620e3f1d55993a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.lambda1 = nn.Parameter(torch.Tensor([math.log(0.5)]), requires_grad=True)\n",
    "        self.lambda2 = nn.Parameter(torch.Tensor([math.log(0.1)]), requires_grad=True)\n",
    "\n",
    "        self.loss_function = nn.MSELoss()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, *input_data):\n",
    "        return self.network(torch.stack(input_data, dim=1))"
   ],
   "id": "22bd17b85a3295ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "def pde_loss(model: PINN, x, y, t, u, v):\n",
    "    x.requires_grad = True\n",
    "    y.requires_grad = True\n",
    "    t.requires_grad = True\n",
    "\n",
    "    u_pred, v_pred, p_pred = model(x, y, t).T\n",
    "    u_t = torch.autograd.grad(u_pred, t, grad_outputs=torch.ones_like(u_pred), retain_graph=True, create_graph=True)[0]\n",
    "    u_x = torch.autograd.grad(u_pred, x, grad_outputs=torch.ones_like(u_pred), retain_graph=True, create_graph=True)[0]\n",
    "    u_y = torch.autograd.grad(u_pred, y, grad_outputs=torch.ones_like(u_pred), retain_graph=True, create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "    u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    v_t = torch.autograd.grad(v_pred, t, grad_outputs=torch.ones_like(v_pred), retain_graph=True, create_graph=True)[0]\n",
    "    v_x = torch.autograd.grad(v_pred, x, grad_outputs=torch.ones_like(v_pred), retain_graph=True, create_graph=True)[0]\n",
    "    v_y = torch.autograd.grad(v_pred, y, grad_outputs=torch.ones_like(v_pred), retain_graph=True, create_graph=True)[0]\n",
    "    v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), retain_graph=True, create_graph=True)[0]\n",
    "    v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(v_y), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    p_x = torch.autograd.grad(p_pred, x, grad_outputs=torch.ones_like(p_pred), retain_graph=True, create_graph=True)[0]\n",
    "    p_y = torch.autograd.grad(p_pred, y, grad_outputs=torch.ones_like(p_pred), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    pde_loss_u = (u_t + torch.exp(model.lambda1) * (u * u_x + v * u_y) + p_x - torch.exp(model.lambda2) * (\n",
    "            u_xx + u_yy)).pow(2).mean()\n",
    "    loss_pred_u = (u_pred - u).pow(2).mean()\n",
    "    # #\n",
    "    pde_loss_v = (v_t + torch.exp(model.lambda1) * (u * v_x + v * v_y) + p_y - torch.exp(model.lambda2) * (\n",
    "            v_xx + v_yy)).pow(2).mean()\n",
    "    loss_pred_v = (v_pred - v).pow(2).mean()\n",
    "    incompressible_loss = (u_x + v_y).pow(2).mean()\n",
    "    return loss_pred_u + loss_pred_v + pde_loss_u + pde_loss_v + incompressible_loss"
   ],
   "id": "677451ac03a7aaaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epoch = 0\n",
    "\n",
    "\n",
    "def train(model, path):\n",
    "    epoch = 0\n",
    "    dataset = load_data(path)\n",
    "    optimizer = torch.optim.LBFGS(\n",
    "        model.parameters(),\n",
    "        lr=1.0,\n",
    "        max_iter=100000,\n",
    "        max_eval=100000,\n",
    "        history_size=50,\n",
    "        tolerance_grad=1e-5,\n",
    "        tolerance_change=1.0 * np.finfo(float).eps,\n",
    "        line_search_fn=\"strong_wolfe\"\n",
    "    )\n",
    "    x, y, t = dataset.x.to(device), dataset.y.to(device), dataset.t.to(device)\n",
    "    u, v, p = dataset.u.to(device), dataset.v.to(device), dataset.p.to(device)\n",
    "\n",
    "    def closure():\n",
    "        global epoch\n",
    "\n",
    "        epoch += 1\n",
    "        optimizer.zero_grad()\n",
    "        loss = pde_loss(model, x, y, t, u, v)\n",
    "        loss.backward()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch}, PDE error: {loss.item()}, lambda1: {torch.exp(model.lambda1).item()}, lambda2: {torch.exp(model.lambda2).item()}\")\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ],
   "id": "671b907562c22de8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gc.collect()\n",
   "id": "7f7e5c35e1845136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = PINN(3, 3, 20).to(device)\n",
    "train(model, \"/content/cylinder_nektar_wake.mat\")"
   ],
   "id": "a412a1220f60c4f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds = load_data(\"./data/cylinder_nektar_wake.mat\")\n",
    "len(ds)"
   ],
   "id": "53195074fa3ee9fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = PINN(3, 3, 20)\n",
    "model.load_state_dict(torch.load(\"./model.weights\", weights_only=True, map_location=device))"
   ],
   "id": "4da310df7bf30c08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def draw_with_bar(data, bounds, path=None):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "\n",
    "    gr = ax.imshow(data, cmap='coolwarm', origin=\"lower\", extent=bounds, vmin=-3, vmax=3)\n",
    "    axis = inset_axes(ax, width=\"5%\", height=\"100%\", loc='upper left', bbox_to_anchor=(1.01, 0, 1, 1),\n",
    "                      bbox_transform=ax.transAxes, borderpad=0, )\n",
    "    axis.tick_params(labelright=True, labelleft=False)\n",
    "    plt.colorbar(gr, cax=axis)\n",
    "    if path is not None: plt.savefig(path)\n",
    "\n",
    "\n",
    "def draw_data(path):\n",
    "    dataset = load_data(path)\n",
    "    bounds = [dataset.x.min(), dataset.x.max(), dataset.y.min(), dataset.y.max()]\n",
    "\n",
    "    for iteration, t in enumerate(np.unique(dataset.t)):\n",
    "        data = dataset[dataset[:][2] == t][5]\n",
    "        data = data.reshape((dataset.x_size, dataset.y_size))\n",
    "\n",
    "        draw_with_bar(data, bounds, path)\n",
    "\n",
    "    import imageio.v2 as imageio\n",
    "\n",
    "    with imageio.get_writer('animation.gif', mode='I') as writer:\n",
    "        for i in range(200):\n",
    "            writer.append_data(imageio.imread(f\"./images/{str(i)}.png\"))\n",
    "\n",
    "\n",
    "def draw_p(T, path=None):\n",
    "    bounds = [1, 8, -2, 2]\n",
    "    x_steps = 256\n",
    "    y_steps = 256\n",
    "    x, y, t = [], [], []\n",
    "    for i in range(x_steps + 1):\n",
    "        for j in range(y_steps + 1):\n",
    "            curr_x = bounds[0] + (bounds[1] - bounds[0]) * (i / x_steps)\n",
    "            curr_y = bounds[2] + (bounds[3] - bounds[2]) * (j / y_steps)\n",
    "            x.append(curr_x)\n",
    "            y.append(curr_y)\n",
    "            t.append(T)\n",
    "\n",
    "    x = torch.Tensor(x)\n",
    "    y = torch.Tensor(y)\n",
    "    t = torch.Tensor(t)\n",
    "\n",
    "    pred = model(x, y, t)\n",
    "    pred = pred[:, 2]\n",
    "    pred -= pred.min()\n",
    "    data = pred.reshape((x_steps + 1, y_steps + 1)).T.detach().numpy()\n",
    "\n",
    "    draw_with_bar(data, bounds, path)\n",
    "\n",
    "\n",
    "def compute_derivative(f, axis):\n",
    "    kernel = torch.tensor([-1, 0, 1], dtype=torch.float32).view(1, -1) if axis == 1 else torch.tensor([-1, 0, 1],\n",
    "                                                                                                      dtype=torch.float32).view(\n",
    "        -1, 1)\n",
    "    kernel = kernel / 2.0\n",
    "    kernel = kernel.to(f.device).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    f = f.unsqueeze(0).unsqueeze(0)\n",
    "    grad = torch.nn.functional.conv2d(f, kernel, padding=1)\n",
    "    return grad.squeeze()\n",
    "\n",
    "\n",
    "def crop_to_same_size(tensor1, tensor2):\n",
    "    min_h = min(tensor1.shape[0], tensor2.shape[0])\n",
    "    min_w = min(tensor1.shape[1], tensor2.shape[1])\n",
    "    return tensor1[:min_h, :min_w], tensor2[:min_h, :min_w]\n",
    "\n",
    "\n",
    "def draw_vorticity(T, path=None):\n",
    "    bounds = [1, 8, -2, 2]\n",
    "    x_steps = 800\n",
    "    y_steps = 500\n",
    "    x, y, t = [], [], []\n",
    "    for i in range(x_steps + 1):\n",
    "        for j in range(y_steps + 1):\n",
    "            curr_x = bounds[0] + (bounds[1] - bounds[0]) * (i / x_steps)\n",
    "            curr_y = bounds[2] + (bounds[3] - bounds[2]) * (j / y_steps)\n",
    "            x.append(curr_x)\n",
    "            y.append(curr_y)\n",
    "            t.append(T)\n",
    "\n",
    "    x = torch.Tensor(x)\n",
    "    y = torch.Tensor(y)\n",
    "    t = torch.Tensor(t)\n",
    "\n",
    "    x.requires_grad = True\n",
    "    y.requires_grad = True\n",
    "    t.requires_grad = True\n",
    "\n",
    "    u_pred, v_pred, p_pred = model(x, y, t).T\n",
    "    u_y = torch.autograd.grad(u_pred, y, grad_outputs=torch.ones_like(u_pred), retain_graph=True, create_graph=True)[0]\n",
    "    v_x = torch.autograd.grad(v_pred, x, grad_outputs=torch.ones_like(v_pred), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    vorticity = v_x - u_y\n",
    "    vorticity = vorticity.reshape((x_steps + 1, y_steps + 1)).T.detach().numpy()\n",
    "\n",
    "    draw_with_bar(vorticity, bounds, path)\n"
   ],
   "id": "4ac251f8fd88e49b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "draw_vorticity(0.)",
   "id": "d389a9f3f949bfd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "steps_t = 200\n",
    "min_t, max_t = 0, 5\n",
    "\n",
    "for iteration in range(steps_t):\n",
    "    T = min_t + (max_t - min_t) * (iteration / steps_t)\n",
    "    draw_vorticity(T, path=f\"./images/{iteration}.png\")"
   ],
   "id": "98cee9257c6cf1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T09:39:35.031859Z",
     "start_time": "2024-12-21T09:39:32.742224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "frames = []\n",
    "f = 200\n",
    "for frame_number in range(0, f):\n",
    "    frame = Image.open(f\"./images/{frame_number}.png\")\n",
    "    frames.append(frame)\n",
    "\n",
    "frames[0].save(\n",
    "    'turbulence.gif',\n",
    "    save_all=True,\n",
    "    append_images=frames,\n",
    "    duration=4 * 1000 / f,\n",
    "    loop=0,\n",
    ")"
   ],
   "id": "3f53ef3a109a34d7",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "steps_t = 200\n",
    "min_t, max_t = 0, 5\n",
    "\n",
    "for iteration in range(steps_t):\n",
    "    T = min_t + (max_t - min_t) * (iteration / steps_t)\n",
    "    draw(T, path=f\"./images/{iteration}.png\")"
   ],
   "id": "96aca375eb08156",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
