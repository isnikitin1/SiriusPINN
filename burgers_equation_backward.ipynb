{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from IPython.display import clear_output"
   ],
   "id": "c033362c4de09748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.lambda1 = nn.Parameter(torch.Tensor([math.log(1.1)]), requires_grad=True)\n",
    "        self.lambda2 = nn.Parameter(torch.Tensor([math.log(0.01)]), requires_grad=True)\n",
    "\n",
    "        self.loss_function = nn.MSELoss()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, *input_data):\n",
    "        return self.network(torch.stack(input_data, dim=1)).flatten()\n",
    "\n",
    "\n",
    "last_u_error = 0\n",
    "last_pde_error = 0\n",
    "\n",
    "\n",
    "def pde_loss(model, t, x, u):\n",
    "    global last_u_error, last_pde_error\n",
    "\n",
    "    t.requires_grad = True\n",
    "    x.requires_grad = True\n",
    "\n",
    "    u_pred = model(t, x)\n",
    "\n",
    "    u_t = torch.autograd.grad(\n",
    "        u_pred, t,\n",
    "        grad_outputs=torch.ones_like(u_pred),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "    u_x = torch.autograd.grad(\n",
    "        u_pred, x,\n",
    "        grad_outputs=torch.ones_like(u_pred),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "    u_xx = torch.autograd.grad(\n",
    "        u_x, x,\n",
    "        grad_outputs=torch.ones_like(u_x),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    residue = u_t + torch.exp(model.lambda1) * u_pred * u_x - torch.exp(model.lambda2) * u_xx\n",
    "    last_pde_error = residue.pow(2).mean()\n",
    "    last_u_error = (u_pred - u).pow(2).mean()\n",
    "    return last_u_error + last_pde_error"
   ],
   "id": "17bc1e9aeec03527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "EPOCHS = 10000\n",
    "LEARNING_RATE = 0.015\n",
    "SCHEDULER_RATE = 20\n",
    "GAMMA = 0.9999\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "TRAINING_FRACTION = 0.95"
   ],
   "id": "759225a12a907eb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset generation",
   "id": "22a48690bfb4c3c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import scipy\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, t, x, u):\n",
    "        super(CustomDataset).__init__()\n",
    "        self.t = t\n",
    "        self.x = x\n",
    "        self.u = u\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.t[item], self.x[item], self.u[item]\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    data = scipy.io.loadmat(path)\n",
    "\n",
    "    T = data['t'].flatten()[:, None]\n",
    "    X = data['x'].flatten()[:, None]\n",
    "    U = np.real(data['usol']).T\n",
    "\n",
    "    t, x, u = [], [], []\n",
    "    for i, t_curr in enumerate(T):\n",
    "        for j, x_curr in enumerate(X):\n",
    "            t.append(torch.Tensor(np.array(t_curr)))\n",
    "            x.append(torch.Tensor(np.array(x_curr)))\n",
    "            u.append(torch.Tensor(np.array(U[i][j])))\n",
    "\n",
    "    t = torch.Tensor(t)\n",
    "    x = torch.Tensor(x)\n",
    "    u = torch.Tensor(u)\n",
    "\n",
    "    return CustomDataset(t, x, u)\n",
    "\n",
    "\n",
    "dataset = load_data(\"burgers_shock.mat\")\n",
    "\n",
    "training_dataset, validation_dataset = random_split(dataset,\n",
    "                                                    (int(len(dataset) * TRAINING_FRACTION),\n",
    "                                                     len(dataset) - int(len(dataset) * TRAINING_FRACTION)),\n",
    "                                                    generator=torch.Generator().manual_seed(238)\n",
    "                                                    )\n",
    "\n",
    "training_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
   ],
   "id": "a060282e3d67bc89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Network training",
   "id": "2f90d5adae3c14ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_batch(model, t, x, u, optimizer):\n",
    "    loss = pde_loss(model, t, x, u)\n",
    "    optimizer.zero_grad()\n",
    "    # maybe retain_graph=False\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def validate_batch(model, t, x, u):\n",
    "    loss = pde_loss(model, t, x, u)\n",
    "\n",
    "    return loss.item()\n"
   ],
   "id": "764f7f859d98f2ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def train(model, training_loader, validation_loader, optimizer, scheduler):\n",
    "    training_loss_history, validation_loss_history = [], []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        training_loss = 0\n",
    "        validation_loss = 0\n",
    "        training_cnt = 0\n",
    "        validation_cnt = 0\n",
    "\n",
    "        for i, (t, x, u) in enumerate(training_loader):\n",
    "            training_loss += train_batch(model, t, x, u, optimizer)\n",
    "            training_cnt += 1\n",
    "\n",
    "        for i, (t, x, u) in enumerate(validation_loader):\n",
    "            validation_loss += validate_batch(model, t, x, u)\n",
    "            validation_cnt += 1\n",
    "\n",
    "        training_loss_history.append(training_loss / training_cnt)\n",
    "        validation_loss_history.append(validation_loss / validation_cnt)\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"Epoch {epoch}, PDE error: {last_pde_error.item()}, U Error: {last_u_error.item()}\")\n",
    "            print(\n",
    "                f\"Epoch {epoch}, lambda1: {torch.exp(model.lambda1).item()}, lambda2: {torch.exp(model.lambda2).item()}\")\n",
    "            # plot_t()\n",
    "\n",
    "        if epoch % SCHEDULER_RATE == 0:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "LBFGS_epoch = 0\n",
    "\n",
    "\n",
    "def train_LBFGS(model, dataset: CustomDataset):\n",
    "    optim = torch.optim.LBFGS(\n",
    "        model.parameters(),\n",
    "        lr=1.0,\n",
    "        max_iter=50000,\n",
    "        max_eval=50000,\n",
    "        history_size=50,\n",
    "        tolerance_grad=1e-5,\n",
    "        tolerance_change=1.0 * np.finfo(float).eps,\n",
    "        line_search_fn=\"strong_wolfe\"\n",
    "    )\n",
    "    t = dataset.t\n",
    "    x = dataset.x\n",
    "    u = dataset.u\n",
    "\n",
    "    def closure():\n",
    "        global LBFGS_epoch\n",
    "        LBFGS_epoch += 1\n",
    "        optim.zero_grad()\n",
    "        u_pred = model(t, x)\n",
    "        loss = pde_loss(model, t, x, u)\n",
    "        loss.backward()\n",
    "        print(f\"Epoch {LBFGS_epoch}, PDE error: {last_pde_error.item()}, U Error: {last_u_error.item()}\")\n",
    "        print(\n",
    "            f\"Epoch {LBFGS_epoch}, lambda1: {torch.exp(model.lambda1).item()}, lambda2: {torch.exp(model.lambda2).item()}\")\n",
    "        return loss\n",
    "\n",
    "    optim.step(closure)\n"
   ],
   "id": "49b5ad766e887771",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = PINN(2, 1, 20)",
   "id": "534a35f40d704f15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
    "\n",
    "train(model, training_loader, validation_loader, optimizer, scheduler)"
   ],
   "id": "3d7d0ba765aa34df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_LBFGS(model, dataset)",
   "id": "2ffd429e96872a68",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
