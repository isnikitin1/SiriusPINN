{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "id": "90a744903d523df3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ],
   "id": "fb0922caf54d804"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "748948c59c09a9d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# torch.backends.cudnn.deterministic = True\n",
    "# random.seed(321)\n",
    "# np.random.seed(321)\n",
    "# torch.manual_seed(321)\n",
    "# torch.cuda.manual_seed_all(321)"
   ],
   "id": "e425a10490c5b637"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from math import pi\n",
    "\n",
    "\n",
    "class BackwardModel(nn.Module):\n",
    "    def __init__(self, activation):\n",
    "        super(BackwardModel, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.lambda1 = nn.Parameter(torch.tensor([0.0]), requires_grad=False).to(device)\n",
    "        self.lambda2 = nn.Parameter(torch.log(torch.Tensor([0.01 / pi])), requires_grad=True).to(device)\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            self.activation(),\n",
    "            nn.Linear(64, 64),\n",
    "            self.activation(),\n",
    "            nn.Linear(64, 64),\n",
    "            self.activation(),\n",
    "            nn.Linear(64, 64),\n",
    "            self.activation(),\n",
    "            nn.Linear(64, 64),\n",
    "            self.activation(),\n",
    "            nn.Linear(64, 1),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        return self.layers(torch.stack(args, dim=1)).flatten()"
   ],
   "id": "3f87a862d287d17a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class PBLossEq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PBLossEq, self).__init__()\n",
    "\n",
    "    def forward(self, model: BackwardModel, x, t, u_pred, u):\n",
    "        u_t = torch.autograd.grad(\n",
    "            u_pred, t,\n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_x = torch.autograd.grad(\n",
    "            u_pred, x,\n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x,\n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        return (u_t + torch.exp(model.lambda1) * u * u_x - torch.exp(model.lambda2) * u_xx).pow(2).mean()\n",
    "\n",
    "\n",
    "class PBLossU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PBLossU, self).__init__()\n",
    "\n",
    "    def forward(self, model: BackwardModel, x, t, u_pred, u):\n",
    "        return (u_pred - u).pow(2).mean()"
   ],
   "id": "9231273186b3458d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from random import randint\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, t, x, u):\n",
    "        super(CustomDataset).__init__()\n",
    "        self.t = t\n",
    "        self.x = x\n",
    "        self.u = u\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.t[item], self.x[item], self.u[item]\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    data = scipy.io.loadmat(path)\n",
    "\n",
    "    T = data['t'].flatten()[:, None]\n",
    "    X = data['x'].flatten()[:, None]\n",
    "    U = np.real(data['usol']).T\n",
    "\n",
    "    t, x, u = [], [], []\n",
    "    for i, t_curr in enumerate(T):\n",
    "        for j, x_curr in enumerate(X):\n",
    "            t.append(torch.Tensor(np.array(t_curr)))\n",
    "            x.append(torch.Tensor(np.array(x_curr)))\n",
    "            u.append(torch.Tensor(np.array(U[i][j])))\n",
    "\n",
    "    t = torch.Tensor(t)\n",
    "    x = torch.Tensor(x)\n",
    "    u = torch.Tensor(u)\n",
    "\n",
    "    return CustomDataset(t, x, u)"
   ],
   "id": "4f4df4890b3540b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def train_log(loss_eq, loss_u, example_ct, epoch, lambda1, lambda2):\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"loss_eq\": loss_eq,\n",
    "        \"loss_u\": loss_u,\n",
    "        \"lambda1\": torch.exp(lambda1),\n",
    "        \"lambda2\": torch.exp(lambda2)\n",
    "    }, step=example_ct)\n",
    "\n",
    "\n",
    "def train(model, loader, criterion_eq, criterion_u, optimizer_layers, optimizer_lambdas, config):\n",
    "    wandb.watch(model, criterion_eq, log=\"all\", log_freq=10)\n",
    "    example_ct, batch_ct = 0, 0\n",
    "\n",
    "    scheduler1 = lr_scheduler.ExponentialLR(optimizer_layers, gamma=0.999)\n",
    "    scheduler2 = lr_scheduler.ExponentialLR(optimizer_lambdas, gamma=0.999)\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        for _, (t, x, u) in enumerate(loader):\n",
    "            loss_eq, loss_u = train_batch(epoch, t, x, u, model, optimizer_layers, optimizer_lambdas, scheduler1,\n",
    "                                          scheduler2, criterion_eq, criterion_u)\n",
    "            example_ct += len(t)\n",
    "            batch_ct += 1\n",
    "\n",
    "            if (batch_ct + 1) % 100 == 0:\n",
    "                train_log(loss_eq, loss_u, example_ct, epoch, model.lambda1, model.lambda2)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        draw(model, epoch)\n",
    "    return example_ct, batch_ct\n",
    "\n",
    "\n",
    "def train_batch(epoch, t, x, u, model, optimizer_layers, optimizer_lambdas, scheduler1, scheduler2, criterion_eq,\n",
    "                criterion_u):\n",
    "    t = t.to(device)\n",
    "    x = x.to(device)\n",
    "    u = u.to(device)\n",
    "    t.requires_grad = True\n",
    "    x.requires_grad = True\n",
    "    u_pred = model(t, x)\n",
    "\n",
    "    loss_eq = criterion_eq(model, t, x, u_pred, u)\n",
    "    loss_u = criterion_u(model, t, x, u_pred, u)\n",
    "\n",
    "    optimizer_layers.zero_grad()\n",
    "    optimizer_lambdas.zero_grad()\n",
    "\n",
    "    total_loss = loss_u + loss_eq\n",
    "    total_loss.backward()\n",
    "\n",
    "    optimizer_layers.step()\n",
    "    optimizer_lambdas.step()\n",
    "\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "\n",
    "    return loss_eq.item(), loss_u.item()"
   ],
   "id": "7f8a67e6bf10d944"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    with wandb.init(project=\"PINN Backward model\", config=hyperparameters):\n",
    "        config = wandb.config\n",
    "        model = BackwardModel(\n",
    "            activation=nn.Tanh\n",
    "        )\n",
    "        optimizer_layers = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=config.learning_rate,\n",
    "        )\n",
    "        optimizer_lambdas = optim.Adam(\n",
    "            [model.lambda1, model.lambda2],\n",
    "            lr=config.learning_rate\n",
    "        )\n",
    "\n",
    "        criterion_eq = PBLossEq()\n",
    "        criterion_u = PBLossU()\n",
    "        dataset = load_data(config.dataset)\n",
    "\n",
    "        train_dataset, test_dataset = random_split(\n",
    "            dataset,\n",
    "            (int(len(dataset) * config.test_size), len(dataset) - int(len(dataset) * config.test_size)),\n",
    "            generator=torch.Generator()\n",
    "        )\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "        train(model, train_loader, criterion_eq, criterion_u, optimizer_layers, optimizer_lambdas, config)\n",
    "\n",
    "    return model\n",
    "\n",
    "# def start_train_LBFGS(model):\n",
    "#     criterion = PBLoss()\n",
    "#     dataset = load_data(\"burgers_shock.mat\")\n",
    "#\n",
    "#     train_dataset, test_dataset = random_split(\n",
    "#         dataset,\n",
    "#         (int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)),\n",
    "#         generator=torch.Generator()\n",
    "#     )\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "#\n",
    "#     train_LBFGS(model, train_loader, criterion)\n",
    "#\n",
    "#     return model"
   ],
   "id": "88cf0aba616d2b7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "params = dict(\n",
    "    epochs=100,\n",
    "    batch_size=512,\n",
    "    learning_rate=0.005,\n",
    "    test_size=1,\n",
    "    dataset=\"burgers_shock.mat\",\n",
    ")\n",
    "model = model_pipeline(params)"
   ],
   "id": "1e30b374ac4bc67f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "wandb.finish()\n",
    "wandb.init()\n",
    "model = start_train_LBFGS(model)"
   ],
   "id": "253c5f5f4611f0b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "\n",
    "def draw(model, epoch):\n",
    "    res = 256\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    iters = 6\n",
    "    for it in range(iters + 1):\n",
    "        T = (1 / iters) * it\n",
    "        t, x, u = [], [], []\n",
    "        for i in range(256):\n",
    "            X = torch.Tensor([-1 + i * (2 / 256)])\n",
    "            # pr10int(X)\n",
    "            t.append(torch.tensor([T]))\n",
    "            x.append(X)\n",
    "\n",
    "        t = torch.Tensor(t)\n",
    "        x = torch.Tensor(x)\n",
    "\n",
    "        pred = model(t, x)\n",
    "        plt.plot(x.detach().numpy(), pred.detach().numpy(), markersize=3)\n",
    "    plt.show()\n",
    "    plt.savefig(f\"./images/{epoch}.png\")"
   ],
   "id": "d1f8f557034759fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "res = 256\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "iters = 6\n",
    "for it in range(iters + 1):\n",
    "    T = (1 / iters) * it\n",
    "    t, x, u = [], [], []\n",
    "    for i in range(256):\n",
    "        X = torch.Tensor([-1 + i * (2 / 256)])\n",
    "        # pr10int(X)\n",
    "        t.append(torch.tensor([T]))\n",
    "        x.append(X)\n",
    "\n",
    "    t = torch.Tensor(t)\n",
    "    x = torch.Tensor(x)\n",
    "\n",
    "    pred = model(t, x)\n",
    "    plt.plot(x.detach().numpy(), pred.detach().numpy(), markersize=3)\n",
    "plt.show()"
   ],
   "id": "14d22ffe9c84482e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58b551fab535df1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
